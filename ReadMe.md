# Deep Learning Course (2025)

## Course Description

The course is about Deep Learning, i.e. a new generation of neural network-based methods that have dramatically improved the performance of AI systems in such domains as computer vision, speech recognition, natural language analysis, reinforcement learning, bioinformatics. The course covers the basics of supervised and unsupervised deep learning and other problem statements for training deep neural models. It also covers the details of the two most successful classes of models, namely convolutional networks and models based on the attention mechanism. In terms of application, the class emphasizes computer vision and natural language analysis tasks. The course involves a significant practical component with a large number of practical assignments.

## Course Plan

* **Topic 1:** Introduction.
* **Topic 2:** Convolutional neural nets.
* **Topic 3:** Computer vision with Deep Learning.
* **Topic 4:** Recurrent Nets and Transformers.
* **Topic 5:** Computer vision with Transformers.
* **Topic 6:** Check-pointing, low-precision training.
* **Topic 7:** Metric learning.
* **Topic 8:** Stability and Adversarial Attacks.
* **Topic 9:** Generative Models (VAE, GAN, Diffusion models, LLM).

## Lectures and Seminars

Below is a detailed breakdown of the course topics, including links to lecture slides and seminar materials (student versions and solutions) in Google Colab.
| Topic | Lecture Title                      | Lecturer          | Description                                                                                                                                                                                             | Presentation                       | Seminar (Student)                                                                                                                               | Seminar (Solution)                                                                                                                                  |
| :---- | :--------------------------------- | :---------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :--------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1     | Introduction                       | Ivan Tyukin       | An introductory lecture covering the history of Deep Learning, the architecture of Deep Neural Networks, and the essential backpropagation training method.                                                | [Link to Presentation](https://lms.skoltech.ru/courses/5562/files/folder/Lecture%201?preview=364924) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)]([https://colab.research.google.com/drive/1yM_ooY7ujkt5ozDHaPyBCe-l1sTRROKH?usp=sharing](https://colab.research.google.com/drive/1kHzRO0p52ONdEmA8e7-6IlUtQXg6R6qB?usp=sharing))                             | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1fZSUfULn9Zu0Dq4dhueBaRz5XO1Aym2a?usp=sharing)                                 |
| 2     | Convolutional neural nets          | Aleksandr Mikhalev       | Explore Convolutional Neural Networks (CNNs), covering key concepts like convolution and pooling, the evolution of influential architectures (e.g., LeNet, AlexNet, ResNet), and their impact on computer vision. | [Link to Presentation](https://lms.skoltech.ru/courses/5562/files/folder/Lecture%202?preview=365907) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Pp5TPXzTt4wq80ryacY_SRU4QYQlff2Z?usp=sharing)                             | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1_Fbtusn_o0XcgHhEOAKgaLmfWBa2qClf?usp=sharing)                                 |
| 3     | Computer vision with Deep Learning | Aleksandr Mikhalev       | Explore key computer vision tasks including edge detection, denoising, super-resolution, object detection, and segmentation. This lecture covers the goal of each task, relevant evaluation metrics, and notable deep learning models. | [Link to Presentation](https://lms.skoltech.ru/courses/5562/files/folder/Lecture%203?preview=366470) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1yM_ooY7ujkt5ozDHaPyBCe-l1sTRROKH?usp=sharing)                             | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ZafQTkkXfuoXNys_1M8moUlvNMK0WupC?usp=sharing)                                 |
| 4     | Recurrent Nets and Transformers    | Tatiana Tyukina   | Learn how Recurrent Neural Networks (RNNs), including LSTM and GRU variants, model sequential data. This lecture covers their core concepts, different architectures, and the BPTT training algorithm with its challenges. | [Link to Presentation](https://lms.skoltech.ru/courses/5562/files/folder/Lecture%204?preview=367880) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/121j-g3S6ZNO3rgaXm3KXr791BIBuM5JG?usp=sharing)                             | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1EXHtvXAyODG9qz-n5f9U9KQYQx2L45OG?usp=sharing)                                 |
| 5     | Computer vision with Transformers  | Tatiana Tyukina   | Learn about the concept of Attention and the Transformer model, understanding how Self-Attention replaces recurrence for processing sequential data in both Natural Language Processing and Computer Vision tasks. | [Link to Presentation](https://lms.skoltech.ru/courses/5562/files/folder/Lecture%205?preview=367883) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1v-x9GkxTY7eKb7cyteIzLwzTvEmbQI-s?usp=sharing)                             | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1WlcRcXftAvKjosDhdlVe7O4aaFMwPd5r?usp=sharing)                                 |
| 6     | Check-pointing, low-precision training | Aleksandr Mikhalev   | Explore strategies for scaling deep learning training, including memory efficiency techniques (e.g., mixed-precision, activation checkpointing), optimizers for large batches, learning rate schedules, and distributed parallelism approaches like ZeRO. | [Link to Presentation](https://lms.skoltech.ru/courses/5562/files/folder/Lecture%206?preview=368542) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1kBWYOf13wx_tF4AwRvcPqQm0sHTjVNsz?usp=sharing)                             | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1VQdPKKSTLtI1JeMT5rGKaN7jXy3lQkGa?usp=sharing)                                 |
| 7     | Metric learning                  | Andrey Lovyagin   | Explore the theory and practice of Deep Metric Learning, detailing the evolution from k-NN to learned metrics, common loss functions (contrastive and angular/softmax families), network architectures, and real-world use cases. | [Link to Presentation](https://lms.skoltech.ru/courses/5562/files/folder/Lecture%207?preview=369601) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1CAXzlaXeHydqikudLh8BVSxWshzB2UzJ?usp=sharing)                             | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1pk5tFtEiIIypivWkvd2LLiEB5lxHNwON?usp=sharing)                                 |
| 8     | Stability and Adversarial Attacks  | Ivan Tyukin       | Explore the critical issues of adversarial attacks and AI stability, delving into why accurate models can be surprisingly fragile, the theoretical explanations for these vulnerabilities, and potential defense strategies. | [Link to Presentation](https://lms.skoltech.ru/courses/5562/files/?preview=370282) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1pM4mhwUQEFzzgPOo0Vz_-sm_AWwvtHpZ?usp=sharing)                             | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/17qcwrSL29ayXVEH1Na90X2nI1e0Mlnul?usp=sharing)                                 |
| 9     | Generative Models                  | Andrey Lovyagin   | This presentation explores the theory and practice of Generative Models, covering foundational concepts like MLE and ELBO, and detailing key architectures such as VAEs, GANs, Diffusion Models, and Large Language Models (LLMs), along with their applications. | [Link to Presentation](https://lms.skoltech.ru/courses/5562/files/?preview=371573) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1q-Uhul1Jb7unKB_gU4GXBxYTCaD_pj17?usp=sharing)                             | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/136FyMa05o8tD-gdc0oXOcA51-_Na7Rwq?usp=sharing)                                 |

## Homework Assignments

### Homework 1: Computer Vision

* **Description:** You are going to work on the Galaxy10 DECals dataset. The task is to train a deep learning model classifier for classifying the galaxy types present. The task is considered completed when accuracy of >90% on the test set is achieved.
* **Colab Notebook:** [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1hITxkVtWbjlBVlXG60qeKnvS02m5DaLC?usp=sharing)

### Homework 2: Natural Language Processing (NLP)

* **Description:** You are going to work with the SMS messages dataset. The task is to train a deep learning model for binary classification of SPAM (trash/ad messages). The task is considered completed when F1 of >90% on the test set is achieved.
* **Colab Notebook:** [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/15FnSv-rzuN0tSYTynqQvfRy-el2x_36z?usp=sharing)

## Contact Information

### Lecturers

* Ivan Tyukin: [![Google Scholar](https://img.shields.io/badge/Google%20Scholar-Profile-4285F4?style=for-the-badge&logo=googlescholar&logoColor=white)](https://scholar.google.co.uk/citations?user=DFU2e3kAAAAJ&hl=en)
* Aleksandr Mikhalev: [![Google Scholar](https://img.shields.io/badge/Google%20Scholar-Profile-4285F4?style=for-the-badge&logo=googlescholar&logoColor=white)](https://scholar.google.com/citations?user=S8zmLXYAAAAJ&hl=en)
* Tatiana Tyukina: [![Google Scholar](https://img.shields.io/badge/Google%20Scholar-Profile-4285F4?style=for-the-badge&logo=googlescholar&logoColor=white)](https://scholar.google.com/citations?user=YfiUR6EAAAAJ&hl=en)
* Andrey Lovyagin: [![GitHub](https://img.shields.io/badge/GitHub-Profile-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/NightForger)

### Teaching Assistants (TAs)

* Ilya Olkov: [![GitHub](https://img.shields.io/badge/GitHub-Profile-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/olkovi)
* Daria Voronkova: [![Google Scholar](https://img.shields.io/badge/Google%20Scholar-Profile-4285F4?style=for-the-badge&logo=googlescholar&logoColor=white)](https://scholar.google.com/citations?user=HyljbxIAAAAJ&hl=ru)
* Andrey Lovyagin: [![GitHub](https://img.shields.io/badge/GitHub-Profile-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/NightForger)
