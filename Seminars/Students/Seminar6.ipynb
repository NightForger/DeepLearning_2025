{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v4J91SNYEgT"
      },
      "source": [
        "# Seminar: Hands-on Exploration of Training Techniques\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Welcome to the seminar session! Following the lecture, this notebook provides a series of hands-on modules where we will implement and explore various techniques related to model training, optimization, and resource management in PyTorch.\n",
        "\n",
        "We will cover topics such as:\n",
        "* Training with different numerical precisions (FP32, FP16, AMP) and its impact on memory.\n",
        "* Alternative optimization strategies like Random Search and Coordinate Descent.\n",
        "* Analyzing memory consumption patterns during training.\n",
        "* Memory-efficient optimizers like 8-bit Adam.\n",
        "* The effect of different learning rate schedules.\n",
        "* A structural demonstration of simple Data Parallelism for multi-GPU training.\n",
        "\n",
        "Each section includes explanations and runnable code cells designed for Google Colab. Let's dive in and experiment!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD38O89jfGup"
      },
      "source": [
        "# 1. Training with Different Precisions and Memory Measurement\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Floating-point precision refers to the number of bits used to represent a number. Common types in deep learning are:\n",
        "* **FP32 (Single Precision):** Uses 32 bits. The standard precision, offering a good balance between range and precision.\n",
        "* **FP16 (Half Precision):** Uses 16 bits. Offers significant memory savings (parameters, gradients, activations take half the space) and potential speedups on supported hardware (like NVIDIA T4 GPUs with Tensor Cores). However, it has a smaller range and less precision, which can sometimes lead to numerical instability (overflow/underflow).\n",
        "* **TF32 (TensorFloat-32):** Uses 19 bits (internally on NVIDIA Ampere+ GPUs). A compromise offering the range of FP32 with the precision of FP16, often used by default for `torch.matmul` on newer GPUs. We won't explicitly test this here but it's good to know.\n",
        "* **BF16 (BFloat16):** Uses 16 bits, but with the same exponent range as FP32 and less precision than FP16. Good for stability, less memory, requires specific hardware support.\n",
        "\n",
        "## Techniques We'll Compare\n",
        "\n",
        "1.  **FP32 Training:** The standard baseline. All calculations and storage use `torch.float32`.\n",
        "2.  **Automatic Mixed Precision (AMP):** The recommended approach for using FP16. `torch.cuda.amp` automatically casts operations to FP16 where safe and beneficial, while keeping sensitive operations (like loss calculations or weight updates) in FP32 for stability. It uses `torch.cuda.amp.autocast` and `torch.cuda.amp.GradScaler`.\n",
        "3.  **Pure FP16 Training:** Manually casting the model and data to `torch.float16`. **This is generally NOT recommended for training** as it often leads to numerical instability (gradients becoming zero or NaN). We include it for comparison and to highlight why AMP is preferred.\n",
        "\n",
        "## Goal\n",
        "\n",
        "We will train a Resnet-50 and ViT-small using these three methods and measure the peak GPU memory consumption for each to observe the memory savings offered by lower precision. We will also monitor the loss to see if stability is maintained."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task:\n",
        "1. Learn how to turn on AMP in real life and hot to turn on pure float16.\n",
        "\n",
        "**Useful links:**\n",
        "1. https://huggingface.co/docs/transformers/v4.34.0/main_classes/model (ctrl+f -> half)\n",
        "2. https://pytorch.org/docs/stable/tensors.html"
      ],
      "metadata": {
        "id": "VL1rgT__WIPD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h06d58iDLGnE"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNF09TK1nj1u"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.amp import autocast\n",
        "\n",
        "# Configuration\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = 224\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize CUDA before any memory operations\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.init()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Memory tracking utilities\n",
        "class MemoryTracker:\n",
        "    def __init__(self):\n",
        "        self.components = {}\n",
        "\n",
        "    def record(self, name):\n",
        "        def hook(module, inp, outp):\n",
        "            self.components[name] = outp.element_size() * outp.nelement()\n",
        "        return hook\n",
        "\n",
        "def get_model_memory(model, input_size=(3, 224, 224)):\n",
        "    tracker = MemoryTracker()\n",
        "    hooks = []\n",
        "\n",
        "    # Register hooks on all layers\n",
        "    for name, layer in model.named_modules():\n",
        "        if name:  # Skip root module\n",
        "            hooks.append(layer.register_forward_hook(tracker.record(name)))\n",
        "\n",
        "    # Run dummy forward\n",
        "    with torch.no_grad():\n",
        "        model(torch.randn(1, *input_size).to(DEVICE))\n",
        "\n",
        "    # Remove hooks\n",
        "    for hook in hooks:\n",
        "        hook.remove()\n",
        "\n",
        "    return tracker.components\n",
        "\n",
        "# Modified Vision Transformer (Small)\n",
        "def create_vit_small():\n",
        "    from torchvision.models.vision_transformer import VisionTransformer\n",
        "    return VisionTransformer(\n",
        "        image_size=IMG_SIZE,\n",
        "        patch_size=16,\n",
        "        num_layers=6,\n",
        "        num_heads=8,\n",
        "        hidden_dim=384,\n",
        "        mlp_dim=1536,\n",
        "        num_classes=1000\n",
        "    )\n",
        "\n",
        "# Memory measurement function\n",
        "def measure_memory(model, optimizer, input_dtype, use_amp):\n",
        "    model.train()\n",
        "    torch.cuda.synchronize()  # Add synchronization\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Initialize scaler only if AMP is enabled\n",
        "    scaler = torch.amp.GradScaler(enabled=use_amp) if use_amp else None\n",
        "\n",
        "    # Create dummy data\n",
        "    inputs = torch.randn(BATCH_SIZE, 3, IMG_SIZE, IMG_SIZE, device=DEVICE, dtype=input_dtype)\n",
        "    targets = torch.randint(0, 1000, (BATCH_SIZE,), device=DEVICE)\n",
        "\n",
        "    # Warmup run\n",
        "    optimizer.zero_grad()\n",
        "    with autocast(device_type='cuda', enabled=use_amp):\n",
        "        outputs = model(inputs)\n",
        "        loss = nn.CrossEntropyLoss()(outputs, targets)\n",
        "\n",
        "    if use_amp:\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "    else:\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Measurement run\n",
        "    torch.cuda.synchronize()\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    with autocast(device_type='cuda', enabled=use_amp):\n",
        "        outputs = model(inputs)\n",
        "        loss = nn.CrossEntropyLoss()(outputs, targets)\n",
        "\n",
        "    if use_amp:\n",
        "        scaler.scale(loss).backward()\n",
        "    else:\n",
        "        loss.backward()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    peak_memory = torch.cuda.max_memory_allocated()\n",
        "\n",
        "    # Component breakdown\n",
        "    param_mem = sum(p.numel() * p.element_size() for p in model.parameters())\n",
        "    grad_mem = sum(p.grad.numel() * p.grad.element_size() for p in model.parameters() if p.grad is not None)\n",
        "\n",
        "    # Optimizer states\n",
        "    optim_mem = sum(\n",
        "        t.numel() * t.element_size()\n",
        "        for state in optimizer.state.values()\n",
        "        for t in state.values() if isinstance(t, torch.Tensor)\n",
        "    )\n",
        "\n",
        "    activation_mem = max(0, peak_memory - param_mem - grad_mem - optim_mem)\n",
        "\n",
        "    return {\n",
        "        'parameters': param_mem,\n",
        "        'gradients': grad_mem,\n",
        "        'optimizer': optim_mem,\n",
        "        'activations': activation_mem\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "def plot_results(results, model_name):\n",
        "    precisions = ['float32', 'mixed', 'float16']\n",
        "    components = ['parameters', 'gradients', 'optimizer', 'activations']\n",
        "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "    bar_width = 0.2\n",
        "    indices = np.arange(len(precisions))\n",
        "\n",
        "    for i, component in enumerate(components):\n",
        "        values = [results[precision][component] for precision in precisions]\n",
        "        ax.bar(indices + i*bar_width, values, bar_width,\n",
        "               label=component, color=colors[i])\n",
        "\n",
        "    ax.set_title(f'Memory Consumption - {model_name}', fontsize=14)\n",
        "    ax.set_ylabel('Memory (MB)', fontsize=12)\n",
        "    ax.set_xticks(indices + bar_width*1.5)\n",
        "    ax.set_xticklabels([p.upper() for p in precisions], fontsize=12)\n",
        "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz8KSC-DK7bY"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObjsILuEK9LJ"
      },
      "outputs": [],
      "source": [
        "def train_and_measure(model_name, precision):\n",
        "    # Model setup\n",
        "    if model_name == 'resnet50':\n",
        "        model = models.resnet50(pretrained=False).to(DEVICE)\n",
        "    elif model_name == 'vit_small':\n",
        "        model = create_vit_small().to(DEVICE)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model\")\n",
        "\n",
        "    input_dtype = torch.float32\n",
        "    use_amp = False\n",
        "\n",
        "    # Precision setup\n",
        "    if precision == 'mixed':\n",
        "        model = model.float()\n",
        "        use_amp = <YOUR_CODE>  # Enable AMP for mixed precision\n",
        "    elif precision == 'float16':\n",
        "        model = <YOUR_CODE> # model.<something here>\n",
        "        input_dtype = <YOUR_CODE> # witch torch.float we need?\n",
        "        use_amp = <YOUR_CODE>  # Disable AMP for pure float16\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
        "\n",
        "    # Measure memory with proper arguments\n",
        "    measurements = measure_memory(model, optimizer, input_dtype, use_amp)\n",
        "\n",
        "    # Convert to MB\n",
        "    return {k: v/(1024**2) for k, v in measurements.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qli4A9FOLAKJ"
      },
      "outputs": [],
      "source": [
        "models_to_test = ['resnet50', 'vit_small']\n",
        "results = {}\n",
        "\n",
        "for model_name in models_to_test:\n",
        "    model_results = {}\n",
        "    print(f\"\\n{'='*50}\\nTesting {model_name.upper()}\\n{'='*50}\")\n",
        "    for precision in ['float32', 'mixed', 'float16']:\n",
        "        print(f\"\\nPrecision: {precision.upper()}\")\n",
        "        model_results[precision] = train_and_measure(model_name, precision)\n",
        "\n",
        "        # Print detailed memory breakdown\n",
        "        mem_data = model_results[precision]\n",
        "        total = sum(mem_data.values())\n",
        "        print(f\"Parameters: {mem_data['parameters']:.2f} MB\")\n",
        "        print(f\"Gradients: {mem_data['gradients']:.2f} MB\")\n",
        "        print(f\"Optimizer states: {mem_data['optimizer']:.2f} MB\")\n",
        "        print(f\"Activations: {mem_data['activations']:.2f} MB\")\n",
        "        print(f\"TOTAL MEMORY: {total:.2f} MB\")\n",
        "\n",
        "    results[model_name] = model_results\n",
        "    plot_results(model_results, model_name)\n",
        "\n",
        "# Print summary table\n",
        "print(\"\\n\\nSUMMARY TABLE (Memory in MB)\")\n",
        "print(\"{:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10}\".format(\n",
        "    \"Model\", \"Precision\", \"Params\", \"Grads\", \"Opt States\", \"Activations\", \"Total\"))\n",
        "\n",
        "for model_name in models_to_test:\n",
        "    for precision in ['float32', 'mixed', 'float16']:\n",
        "        mem = results[model_name][precision]\n",
        "        total = sum(mem.values())\n",
        "        print(\"{:<10} {:<10} {:<10.1f} {:<10.1f} {:<10.1f} {:<10.1f} {:<10.1f}\".format(\n",
        "            model_name,\n",
        "            precision,\n",
        "            mem['parameters'],\n",
        "            mem['gradients'],\n",
        "            mem['optimizer'],\n",
        "            mem['activations'],\n",
        "            total\n",
        "        ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHaPx_fmlnds"
      },
      "source": [
        "# 2. 8-bit Adam vs. 32-bit Adam\n",
        "\n",
        "## Introduction\n",
        "\n",
        "The Adam optimizer is highly effective but memory-intensive. For each model parameter (typically FP32), Adam stores two additional FP32 values:\n",
        "1.  **First Moment (Momentum):** An exponentially decaying average of past gradients.\n",
        "2.  **Second Moment (Variance):** An exponentially decaying average of past squared gradients.\n",
        "\n",
        "This means Adam roughly *triples* the memory required compared to storing only the parameters themselves (e.g., for inference or SGD with no momentum). This memory usage can become a bottleneck, preventing the use of larger models or batch sizes.\n",
        "\n",
        "## 8-bit Adam\n",
        "\n",
        "To address this, techniques like 8-bit Adam have been developed. The core idea is to store the optimizer states (first and second moments) using only 8 bits per value, drastically reducing their memory footprint (a 4x reduction compared to FP32 states).\n",
        "\n",
        "This is achieved through **quantization**: representing the FP32 state values using a smaller set of 8-bit values. To maintain performance, 8-bit optimizers often use sophisticated techniques like:\n",
        "* **Block-wise Quantization:** Quantizing small blocks of the state tensor independently to adapt to varying value ranges.\n",
        "* **Dynamic Quantization:** Using quantiles or dynamic ranges rather than simple min-max scaling.\n",
        "\n",
        "We will use the `bitsandbytes` library, which provides a highly optimized implementation of 8-bit Adam (`Adam8bit`).\n",
        "\n",
        "## Goal\n",
        "\n",
        "We will train the same model using:\n",
        "1.  Standard `torch.optim.Adam` (32-bit states).\n",
        "2.  `bitsandbytes.optim.Adam8bit` (8-bit states).\n",
        "\n",
        "We will measure the peak GPU memory consumption for both and compare their training loss curves to see the memory savings and assess any potential impact on convergence."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task:\n",
        "1. Learn how to use Adam (32bit and 8 bit) in real life easily.\n",
        "\n",
        "**Useful links:**\n",
        "1. Use optim library to use Adam (32 bit), dont forget about lr and weight_decay: https://pytorch.org/docs/stable/generated/torch.optim.Adam.html\n",
        "2. Use bnb library to use Adam (8 bit), dont forget about lr and weight_decay: https://huggingface.co/docs/bitsandbytes/v0.43.2/optimizers"
      ],
      "metadata": {
        "id": "js8qYWLsXbUJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbSP-OSBbsYv"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAI5I180busT",
        "outputId": "102d19e5-f9fd-4f4a-b65e-81c24517e71d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m895.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDevice in use: cuda\n"
          ]
        }
      ],
      "source": [
        "%pip install bitsandbytes torchvision matplotlib numpy torch -q\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import bitsandbytes as bnb\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device in use:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xypce0ecb2gf",
        "outputId": "e4904d7d-83aa-4010-d3e9-f1eef5e5c51e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:10<00:00, 15.6MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size xb (images): torch.Size([128, 3, 32, 32])\n",
            "Batch size yb (labels): torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "# Augmentation + normalization\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                         (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                         (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True,\n",
        "                          drop_last=True, generator=g, num_workers=2)\n",
        "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False,\n",
        "                         drop_last=False, generator=g, num_workers=2)\n",
        "\n",
        "xb, yb = next(iter(train_loader))\n",
        "print(\"Batch size xb (images):\", xb.shape)\n",
        "print(\"Batch size yb (labels):\", yb.shape)\n",
        "\n",
        "# Model with BatchNorm + Dropout\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        # First block\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1   = nn.BatchNorm2d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Second block\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2   = nn.BatchNorm2d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Fully-connected layers\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(8*8*64, 512)\n",
        "        self.bn3 = nn.BatchNorm1d(512)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def train_one_epoch(model, optimizer, loader, loss_fn, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    start_time = time.time()\n",
        "    for i, (Xb, yb) in enumerate(loader):\n",
        "        Xb, yb = Xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        logits = model(Xb)\n",
        "        loss = loss_fn(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    epoch_time = time.time() - start_time\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    return avg_loss, epoch_time\n",
        "\n",
        "def evaluate(model, loader, loss_fn, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for Xb, yb in loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            logits = model(Xb)\n",
        "            loss = loss_fn(logits, yb)\n",
        "            total_loss += loss.item()\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            total_correct += (preds == yb).sum().item()\n",
        "            total_samples += yb.size(0)\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    accuracy = 100.0 * total_correct / total_samples\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_a9sTuhcgVu"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kDtZTARXWsn8"
      },
      "outputs": [],
      "source": [
        "def train_with_optimizer(optimizer_name, epochs=10, lr=1e-3, wd=0.0):\n",
        "    print(f\"\\n=== Training with {optimizer_name} ===\")\n",
        "    model = SimpleCNN(num_classes=10).to(device)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats(device)\n",
        "    start_mem = torch.cuda.memory_allocated(device)\n",
        "    print(f\"Initial GPU memory allocation: {start_mem / 1024**2:.2f} MB\")\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Number of trainable parameters: {total_params:,}\")\n",
        "\n",
        "    # Select the optimizer\n",
        "    if optimizer_name == \"Adam (32-bit)\":\n",
        "        optimizer = <YOUR_CODE>\n",
        "    elif optimizer_name == \"Adam (8-bit)\":\n",
        "        optimizer = <YOUR_CODE>\n",
        "        print(\"bitsandbytes: Adam8bit is used.\")\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    history = {'train_loss': [], 'val_loss': [], 'val_acc': [], 'epoch_time': []}\n",
        "    total_train_time = 0\n",
        "\n",
        "    print(f\"Starting training for {epochs} epochs...\")\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        tr_loss, epoch_time = train_one_epoch(model, optimizer,\n",
        "                                              train_loader, loss_fn, device)\n",
        "        val_loss, val_acc = evaluate(model, test_loader, loss_fn, device)\n",
        "\n",
        "        history['train_loss'].append(tr_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['epoch_time'].append(epoch_time)\n",
        "        total_train_time += epoch_time\n",
        "\n",
        "        print(f\"[Epoch {epoch}/{epochs}] \"\n",
        "              f\"Time: {epoch_time:.2f}s | \"\n",
        "              f\"Train Loss: {tr_loss:.4f} | \"\n",
        "              f\"Val Loss: {val_loss:.4f} | \"\n",
        "              f\"Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    print(f\"Total training time: {total_train_time:.2f} s.\")\n",
        "\n",
        "    peak_mem = torch.cuda.max_memory_allocated(device)\n",
        "    print(f\"Peak GPU memory usage: {peak_mem / 1024**2:.2f} MB\")\n",
        "    del model, optimizer, loss_fn\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return peak_mem, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e5mIjqr8ccK0"
      },
      "outputs": [],
      "source": [
        "peak_mem_32, history_32 = train_with_optimizer(\n",
        "    \"Adam (32-bit)\", epochs=10, lr=1e-3, wd=1e-4\n",
        ")\n",
        "peak_mem_8, history_8 = train_with_optimizer(\n",
        "    \"Adam (8-bit)\",  epochs=10, lr=1e-3, wd=1e-4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BE1ZEJ_sceYi"
      },
      "outputs": [],
      "source": [
        "# Visualization\n",
        "train_losses_32 = history_32['train_loss']\n",
        "val_acc_32      = history_32['val_acc']\n",
        "times_32        = history_32['epoch_time']\n",
        "\n",
        "train_losses_8  = history_8['train_loss']\n",
        "val_acc_8       = history_8['val_acc']\n",
        "times_8         = history_8['epoch_time']\n",
        "\n",
        "epochs_range = range(1, len(train_losses_32) + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Train Loss\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(epochs_range, train_losses_32, label='Train Loss (Adam 32-bit)', marker='o')\n",
        "plt.plot(epochs_range, train_losses_8, label='Train Loss (Adam 8-bit)', linestyle='--', marker='x')\n",
        "plt.title('Train Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Validation Accuracy\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(epochs_range, val_acc_32, label='Val Acc (Adam 32-bit)', marker='o')\n",
        "plt.plot(epochs_range, val_acc_8, label='Val Acc (Adam 8-bit)', linestyle='--', marker='x')\n",
        "plt.title('Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Time per Epoch\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(epochs_range, times_32, label='Epoch Time (Adam 32-bit)', marker='o')\n",
        "plt.plot(epochs_range, times_8,  label='Epoch Time (Adam 8-bit)', linestyle='--', marker='x')\n",
        "plt.title('Time per Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Seconds')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgqJdeb1lrEm"
      },
      "source": [
        "# 3. Learning Rate Schedules\n",
        "\n",
        "## Introduction\n",
        "\n",
        "The **learning rate (LR)** is a crucial hyperparameter in training neural networks. It determines the step size taken during parameter updates based on the calculated gradients. Choosing a fixed learning rate can be challenging:\n",
        "* **Too High:** May cause divergence or overshoot the minimum.\n",
        "* **Too Low:** May lead to very slow convergence or getting stuck in poor local minima.\n",
        "\n",
        "**Learning Rate Schedules** address this by dynamically adjusting the learning rate during training. The goal is often to start with a relatively high LR to make quick progress early on and then decrease it later to allow for finer adjustments and more stable convergence near a minimum.\n",
        "\n",
        "## Common LR Scheduless in PyTorch\n",
        "\n",
        "We will explore a few common schedules available in `torch.optim.lr_scheduler`:\n",
        "\n",
        "1.  **Constant LR (Baseline):** No schedule is used; the learning rate remains fixed throughout training.\n",
        "2.  **StepLR:** Decreases the learning rate by a factor (`gamma`) every specified number of epochs (`step_size`). Simple and effective, but can cause sudden drops in training progress.\n",
        "    * `scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)`\n",
        "3.  **ExponentialLR:** Multiplies the learning rate by a factor (`gamma`) after each epoch. Provides a smoother decay than StepLR.\n",
        "    * `scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)`\n",
        "4.  **CosineAnnealingLR:** Smoothly anneals the learning rate from an initial value down to a minimum value (`eta_min`, often 0) over a specified number of epochs (`T_max`), following a cosine curve. It's often restarted (`CosineAnnealingWarmRestarts`). This is a popular and often effective schedule.\n",
        "    * `scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0)`\n",
        "\n",
        "## Goal\n",
        "\n",
        "To train the same model with a fixed (constant) learning rate and compare its loss curve against training runs using StepLR, ExponentialLR, and CosineAnnealingLR. We will visualize both the loss curves and the learning rate changes over time for each schedule."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task:\n",
        "1. Learn how to use different Schedulers in real life easily.\n",
        "\n",
        "**Useful links:**\n",
        "1. https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html (step_size=5, gamma=0.1)\n",
        "2. https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ExponentialLR.html (gamma=0.9)\n",
        "3. https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingLR.html (T_max=num_epochs, eta_min=1e-5)"
      ],
      "metadata": {
        "id": "7OECUFHlY0e3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mUbXZrRdPzz"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k9Ta-WudRIe",
        "outputId": "05f78017-73ae-435f-d383-d35d68b06322"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "# Import LR schedulers\n",
        "from torch.optim.lr_scheduler import StepLR, ExponentialLR, CosineAnnealingLR\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n",
        "\n",
        "# Seeding\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Ensure that CUDA is available\n",
        "if not torch.cuda.is_available():\n",
        "    raise SystemError(\"CUDA is not available. This code requires a GPU.\")\n",
        "device = torch.device(\"cuda\")\n",
        "print(f\"Using device: {torch.cuda.get_device_name(device)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7G9QEt-bia39"
      },
      "outputs": [],
      "source": [
        "# Loading the actual FashionMNIST dataset\n",
        "def get_fashion_mnist_loaders(batch_size=128):\n",
        "    \"\"\"\n",
        "    Load the train/test FashionMNIST datasets and create DataLoaders.\n",
        "    Add minor augmentations (RandomCrop, Flip).\n",
        "    \"\"\"\n",
        "    # Augmentations for training\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(28, padding=2),     # a bit of \"virtual\" padding\n",
        "        transforms.RandomHorizontalFlip(),         # horizontal flips\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # For testing — without any augmentations\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    train_dataset = torchvision.datasets.FashionMNIST(\n",
        "        root='./data_fashion', train=True,\n",
        "        transform=transform_train, download=True\n",
        "    )\n",
        "    test_dataset = torchvision.datasets.FashionMNIST(\n",
        "        root='./data_fashion', train=False,\n",
        "        transform=transform_test, download=True\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=batch_size,\n",
        "        shuffle=True, num_workers=2, drop_last=True\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, batch_size=batch_size,\n",
        "        shuffle=False, num_workers=2, drop_last=False\n",
        "    )\n",
        "    return train_loader, test_loader\n",
        "\n",
        "# Model\n",
        "def get_model(num_classes=10):\n",
        "    \"\"\"\n",
        "    A simple CNN model with BatchNorm and Dropout.\n",
        "    Input: (batch_size, 1, 28, 28) for FashionMNIST data.\n",
        "    \"\"\"\n",
        "    class SimpleCNN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "            self.bn1   = nn.BatchNorm2d(32)\n",
        "            self.relu1 = nn.ReLU()\n",
        "            self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "            self.bn2   = nn.BatchNorm2d(64)\n",
        "            self.relu2 = nn.ReLU()\n",
        "            self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "            self.flatten = nn.Flatten()\n",
        "            self.fc1 = nn.Linear(7 * 7 * 64, 128)\n",
        "            self.bn3 = nn.BatchNorm1d(128)\n",
        "            self.relu3 = nn.ReLU()\n",
        "            self.dropout = nn.Dropout(0.3)\n",
        "            self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.conv1(x)\n",
        "            x = self.bn1(x)\n",
        "            x = self.relu1(x)\n",
        "            x = self.pool1(x)\n",
        "\n",
        "            x = self.conv2(x)\n",
        "            x = self.bn2(x)\n",
        "            x = self.relu2(x)\n",
        "            x = self.pool2(x)\n",
        "\n",
        "            x = self.flatten(x)\n",
        "            x = self.fc1(x)\n",
        "            x = self.bn3(x)\n",
        "            x = self.relu3(x)\n",
        "            x = self.dropout(x)\n",
        "            x = self.fc2(x)\n",
        "            return x\n",
        "\n",
        "    return SimpleCNN()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AL4t38cdRUn"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C9CcvUP2Wsta"
      },
      "outputs": [],
      "source": [
        "# Training function with schedulers\n",
        "def train_with_scheduler(scheduler_type, initial_lr=1e-3, num_epochs=20,\n",
        "                         batch_size=128, steps_per_epoch=20):\n",
        "    \"\"\"\n",
        "    Trains a CNN on FashionMNIST with different LR schedulers.\n",
        "    steps_per_epoch: number of batches to use per epoch (for speed).\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Training with {scheduler_type} LR Schedule ---\")\n",
        "\n",
        "    # FashionMNIST data\n",
        "    train_loader, test_loader = get_fashion_mnist_loaders(batch_size=batch_size)\n",
        "\n",
        "    # Create model, loss function, and optimizer\n",
        "    model = get_model(num_classes=10).to(device)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
        "\n",
        "    # Initialize the scheduler\n",
        "    scheduler = None\n",
        "    if scheduler_type == 'Constant':\n",
        "        pass\n",
        "    elif scheduler_type == 'StepLR':\n",
        "        # Reduce LR by a factor of 10 every 5 epochs\n",
        "        scheduler = <YOUR_CODE>\n",
        "    elif scheduler_type == 'ExponentialLR':\n",
        "        # Multiply LR by 0.9 each epoch\n",
        "        scheduler = <YOUR_CODE>\n",
        "    elif scheduler_type == 'CosineAnnealingLR':\n",
        "        # Cosine annealing function\n",
        "        scheduler = <YOUR_CODE>\n",
        "\n",
        "    epoch_losses = []\n",
        "    learning_rates = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_iter = iter(train_loader)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss_sum = 0\n",
        "        for _ in range(steps_per_epoch):\n",
        "            try:\n",
        "                data, targets = next(train_iter)\n",
        "            except StopIteration:\n",
        "                train_iter = iter(train_loader)\n",
        "                data, targets = next(train_iter)\n",
        "\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(data)\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss_sum += loss.item()\n",
        "\n",
        "        avg_epoch_loss = epoch_loss_sum / steps_per_epoch\n",
        "        epoch_losses.append(avg_epoch_loss)\n",
        "\n",
        "        # Check the current LR before stepping\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        learning_rates.append(current_lr)\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        # Print loss and LR every few epochs\n",
        "        if (epoch + 1) % max(1, num_epochs // 5) == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "                  f\"Avg Loss: {avg_epoch_loss:.4f}, LR: {current_lr:.6f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Training finished in {end_time - start_time:.2f} seconds.\")\n",
        "\n",
        "    del model, optimizer, loss_fn, data, targets, outputs, loss, scheduler\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return epoch_losses, learning_rates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HjABbJSgiuBp"
      },
      "outputs": [],
      "source": [
        "# Running training for different schedulers\n",
        "schedule_results = {}\n",
        "num_epochs_sched = 20\n",
        "initial_lr_sched = 1e-3\n",
        "\n",
        "schedule_types = ['Constant', 'StepLR', 'ExponentialLR', 'CosineAnnealingLR']\n",
        "\n",
        "for sched_type in schedule_types:\n",
        "    losses, lrs = train_with_scheduler(\n",
        "        sched_type,\n",
        "        initial_lr=initial_lr_sched,\n",
        "        num_epochs=num_epochs_sched,\n",
        "        steps_per_epoch=20\n",
        "    )\n",
        "    schedule_results[sched_type] = {'losses': losses, 'lrs': lrs}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fPfIcXaSivZF"
      },
      "outputs": [],
      "source": [
        "# Visualization\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "epochs = range(1, num_epochs_sched + 1)\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, len(schedule_types)))  # Use a colormap\n",
        "\n",
        "# Loss Curves Plot\n",
        "fig_loss_sched, ax_loss_sched = plt.subplots(1, 1, figsize=(12, 6))\n",
        "for i, sched_type in enumerate(schedule_types):\n",
        "    if sched_type in schedule_results:\n",
        "        raw_losses = schedule_results[sched_type]['losses']\n",
        "\n",
        "        # Plot losses\n",
        "        ax_loss_sched.plot(epochs, raw_losses,\n",
        "                           label=f'{sched_type} Loss (raw)',\n",
        "                           color=colors[i], linewidth=1)\n",
        "\n",
        "ax_loss_sched.set_xlabel('Epochs')\n",
        "ax_loss_sched.set_ylabel('Average Loss')\n",
        "ax_loss_sched.set_title('Training Loss (Raw vs Smoothed) with Different LR Schedules (FashionMNIST)')\n",
        "ax_loss_sched.legend()\n",
        "ax_loss_sched.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Learning Rate Plot\n",
        "fig_lr, ax_lr = plt.subplots(1, 1, figsize=(12, 6))\n",
        "for i, sched_type in enumerate(schedule_types):\n",
        "    if sched_type in schedule_results:\n",
        "        lrs = schedule_results[sched_type]['lrs']\n",
        "        ax_lr.plot(epochs, lrs,\n",
        "                   label=f'{sched_type} LR',\n",
        "                   color=colors[i], linewidth=2,\n",
        "                   linestyle='--' if i % 2 else '-')\n",
        "ax_lr.set_xlabel('Epochs')\n",
        "ax_lr.set_ylabel('Learning Rate')\n",
        "ax_lr.set_title('Learning Rate Evolution for Different Schedules (FashionMNIST)')\n",
        "ax_lr.legend()\n",
        "ax_lr.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI7X0zSt9O5_"
      },
      "source": [
        "# 4. Training without backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzxacWh3Hej7"
      },
      "source": [
        "In the section, we will explore two methods of training with no backpropagation: random search and coordinate desent with approximate derivative.\n",
        "\n",
        "First, for futrther comparison, let us train a network with simple SGD."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task:\n",
        "1. Learn hot to use SGD easily.\n",
        "2. What is random search.\n",
        "3. What is coordinate descent. Which benefit it give and why it is not popular for big models.\n",
        "\n",
        "**Useful links:**\n",
        "1. https://pytorch.org/docs/stable/generated/torch.optim.SGD.html"
      ],
      "metadata": {
        "id": "iu17vtOxZ0ni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites"
      ],
      "metadata": {
        "id": "4GCUI13HZdr8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cB04PRo59WNx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxWg33nmMqrt",
        "outputId": "16fe5eab-ebda-43c4-cd62-34dbfa472762"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 19.9MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 304kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.66MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 12.9MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set has 60000 instances\n",
            "Validation set has 10000 instances\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
        "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
        "\n",
        "print('Training set has {} instances'.format(len(training_set)))\n",
        "print('Validation set has {} instances'.format(len(validation_set)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RzDqFfPN9ett"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 32) # 784 -> 32\n",
        "        self.fc2 = nn.Linear(32, 10)     # 32 -> 10\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1) # Распрямляем\n",
        "        x = F.relu(self.fc1(x))   # Первый слой + активация\n",
        "        x = self.fc2(x)           # Выходной слой\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, optimizer, train_loader, test_loader, device, update_func=None):\n",
        "  history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
        "\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    print (f'EPOCH {epoch+1}/{NUM_EPOCHS}')\n",
        "    print ('-'*10)\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in tqdm(train_loader, desc=f'Training', leave=False):\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      if update_func is None:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = CRITERION(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      else:\n",
        "        model = update_func(model, inputs, labels)\n",
        "        outputs = model(inputs)\n",
        "        loss = CRITERION(outputs, labels)\n",
        "\n",
        "      running_loss += loss.item() * inputs.size(0)\n",
        "      _, predicted = torch.max(outputs, dim=1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    history['train_loss'].append(epoch_loss)\n",
        "    history['train_acc'].append(epoch_acc)\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0.\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for inputs, labels in tqdm(test_loader, desc=f'Testing', leave=False):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = CRITERION(outputs, labels)\n",
        "\n",
        "        test_loss += loss.item() * labels.size(0)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_epoch_loss = test_loss / test_total\n",
        "    test_epoch_acc = test_correct / test_total\n",
        "    history['test_loss'].append(test_epoch_loss)\n",
        "    history['test_acc'].append(test_epoch_acc)\n",
        "\n",
        "    print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "    print(f'Test Loss: {test_epoch_loss:.4f} Acc: {test_epoch_acc:.4f}')\n",
        "\n",
        "  return history"
      ],
      "metadata": {
        "id": "VyxjZ0CDZsPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "Pv69EkSPZkEc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "VP5ciKQp9e2C",
        "outputId": "4117b04d-87c8-4cfd-f216-2e6082628697"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pullover  Coat  Coat  Pullover\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "images = images[:4]\n",
        "labels = labels[:4]\n",
        "\n",
        "# Create a grid from the images and show them\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "matplotlib_imshow(img_grid, one_channel=True)\n",
        "print('  '.join(classes[labels[j]] for j in range(4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Jih4GUuP9sqL"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 5\n",
        "CRITERION = nn.CrossEntropyLoss()\n",
        "LEARNING_RATE = 0.005\n",
        "N_TRIALS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ7_n6eI909s",
        "outputId": "db5a364b-4d50-4b2c-a89d-db924066f646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH 1/5\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.6771 Acc: 0.4160\n",
            "Test Loss: 0.7795 Acc: 0.6939\n",
            "EPOCH 2/5\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6662 Acc: 0.7451\n",
            "Test Loss: 0.6330 Acc: 0.7644\n",
            "EPOCH 3/5\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.5737 Acc: 0.7808\n",
            "Test Loss: 0.5510 Acc: 0.7949\n",
            "EPOCH 4/5\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.5222 Acc: 0.8039\n",
            "Test Loss: 0.5093 Acc: 0.8123\n",
            "EPOCH 5/5\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4866 Acc: 0.8190\n",
            "Test Loss: 0.5141 Acc: 0.8000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "model = Net()\n",
        "model = model.to(device)\n",
        "optimizer = SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "sgd_history = train_model(model, optimizer, train_loader, test_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoxajNTT83HK"
      },
      "source": [
        "## 2. Random search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obYjvTp4GOOX"
      },
      "source": [
        "In this task, we will update the model parameters in random directions that promote loss decrease.\n",
        "\n",
        "1. Compute loss $L_0 = f(x, \\Theta(t))$\n",
        "2. Compute randomly shifted loss $L_1 = f(x, \\Theta(t) + \\Delta)$\n",
        "3. If $L_1 < L_0$, then update $\\Theta(t+1) = \\Theta(t) + \\Delta$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Bg1Mu5fKWs4P"
      },
      "outputs": [],
      "source": [
        "def model_random_update(model):\n",
        "  for p in model.parameters():\n",
        "    if p.requires_grad:\n",
        "      p.data = p.data - LEARNING_RATE * torch.empty(p.shape).normal_(mean=0., std=0.1).to(device)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "17YRf23EWs63"
      },
      "outputs": [],
      "source": [
        "def update_random(model, inputs, labels):\n",
        "  outputs = model(inputs)\n",
        "  min_loss = CRITERION(outputs, labels)\n",
        "# Save a copy of current weights, use copy.deepcopy\n",
        "  cur_weights = <YOUR CODE HERE>\n",
        "# Save a copy of current weights, use copy.deepcopy\n",
        "  min_weights = <YOUR CODE HERE>\n",
        "  for j in range(N_TRIALS):\n",
        "# make a random update\n",
        "    model = <YOUR CODE HERE>\n",
        "    outputs = model(inputs)\n",
        "    cur_loss = CRITERION(outputs, labels)\n",
        "    if cur_loss < min_loss:\n",
        "# Update min_loss\n",
        "      min_loss = <YOUR CODE HERE>\n",
        "# Update min weights\n",
        "      min_weights = <YOUR CODE HERE>\n",
        "# Reload the initial weights\n",
        "    model.load_state_dict(<YOUR CODE HERE>)\n",
        "# Load the best weights found\n",
        "  model.load_state_dict(<YOUR CODE HERE>)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UftyjHzTUzq1",
        "outputId": "343d15e6-e4ee-4426-ddef-150ef2b84c99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH 1/5\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.2589 Acc: 0.2498\n",
            "Test Loss: 2.1605 Acc: 0.3777\n",
            "EPOCH 2/5\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.8945 Acc: 0.4066\n",
            "Test Loss: 1.5723 Acc: 0.5254\n",
            "EPOCH 3/5\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.3397 Acc: 0.5506\n",
            "Test Loss: 1.1738 Acc: 0.5778\n",
            "EPOCH 4/5\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.0829 Acc: 0.6248\n",
            "Test Loss: 1.0294 Acc: 0.6383\n",
            "EPOCH 5/5\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.9637 Acc: 0.6568\n",
            "Test Loss: 0.9507 Acc: 0.6534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "model = Net()\n",
        "model = model.to(device)\n",
        "random_history = train_model(model, None, train_loader, test_loader, device, update_random)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJhCj0V5-GK6"
      },
      "source": [
        "## 3. Coordinate Descent with Finite Difference Approximation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFq8EeiQH1OI"
      },
      "source": [
        "For each coordinate in the parameter space, we will compute its approximate derivative via discretization:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial \\Theta_i} \\approx \\frac{f(x, \\Theta(t) + \\delta e_i) - f(x, \\Theta(t))}{\\delta}\n",
        "$$\n",
        "\n",
        "**Why Coordinate Descent is So Hard to Train for modern Neural Networks and Its Problems:**\n",
        "\n",
        "Despite the seeming simplicity of updating parameters one by one, coordinate descent (especially with gradient approximation via finite differences) faces significant challenges when applied to training neural networks.\n",
        "\n",
        "Try to think what problems it has while realising CD by yourself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YJ0sNDEv-BVD"
      },
      "outputs": [],
      "source": [
        "def sample_rand_coord(model):\n",
        "  param_name_size = [(n, p.shape) for n, p in model.named_parameters() if p.requires_grad]\n",
        "  size_cumsum = np.cumsum([0] + [np.prod(s) for n, s in param_name_size])\n",
        "  rand_index = np.random.choice(size_cumsum[-1])\n",
        "  param_index = (size_cumsum <= rand_index).sum() - 1\n",
        "  coord_index = np.unravel_index(rand_index - size_cumsum[param_index], param_name_size[param_index][1])\n",
        "  param_name = param_name_size[param_index][0]\n",
        "  return param_name, coord_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pAHdbPIM-BX4"
      },
      "outputs": [],
      "source": [
        "def model_random_coord_update(model, value, param_name, coord_index):\n",
        "  for n, p in model.named_parameters():\n",
        "    if n == param_name:\n",
        "      p.data[coord_index] = p.data[coord_index] + value\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rZ4mTDww-Baw"
      },
      "outputs": [],
      "source": [
        "def update_coord_approx(model, inputs, labels):\n",
        "  for i in range(N_TRIALS):\n",
        "    outputs = model(inputs)\n",
        "    cur_loss = CRITERION(outputs, labels).item()\n",
        "    cur_weights = copy.deepcopy(model.state_dict())\n",
        "    param_name, coord_index = sample_rand_coord(model)\n",
        "    model = model_random_coord_update(model, DELTA, param_name, coord_index)\n",
        "    outputs = model(inputs)\n",
        "    next_loss = CRITERION(outputs, labels).item()\n",
        "    partial_approx = <YOUR_CODE> # What must be here? How we aprox?\n",
        "    model.load_state_dict(cur_weights)\n",
        "    model = model_random_coord_update(model, -LEARNING_RATE * partial_approx, param_name, coord_index)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x9KrHuD0UztE"
      },
      "outputs": [],
      "source": [
        "DELTA = 2.\n",
        "N_TRIALS = 50\n",
        "LEARNING_RATE = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BK4nHXqF-SgC"
      },
      "outputs": [],
      "source": [
        "model = Net()\n",
        "model = model.to(device)\n",
        "random_coord_history = train_model(model, None, train_loader, test_loader, device, update_coord_approx)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualisation"
      ],
      "metadata": {
        "id": "qB_qpnbybFZx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MgLel17KAMMP"
      },
      "outputs": [],
      "source": [
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(20, 5), tight_layout=True)\n",
        "ax[0].plot(sgd_history['train_loss'], label='SGD')\n",
        "ax[0].plot(random_history['train_loss'], label='Random Search')\n",
        "ax[0].plot(random_coord_history['train_loss'], label='Coord. Descent')\n",
        "ax[0].legend()\n",
        "ax[0].set_title('Train Loss')\n",
        "ax[0].set_xlabel('Epoch')\n",
        "\n",
        "ax[1].plot(sgd_history['test_loss'], label='SGD')\n",
        "ax[1].plot(random_history['test_loss'], label='Random Search')\n",
        "ax[1].plot(random_coord_history['test_loss'], label='Coord. Descent')\n",
        "ax[1].legend()\n",
        "ax[1].set_title('Test Loss')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "\n",
        "ax[2].plot(sgd_history['train_acc'], label='SGD')\n",
        "ax[2].plot(random_history['train_acc'], label='Random Search')\n",
        "ax[2].plot(random_coord_history['train_acc'], label='Coord. Descent')\n",
        "ax[2].legend()\n",
        "ax[2].set_title('Train Accuracy')\n",
        "ax[2].set_xlabel('Epoch')\n",
        "\n",
        "ax[3].plot(sgd_history['test_acc'], label='SGD')\n",
        "ax[3].plot(random_history['test_acc'], label='Random Search')\n",
        "ax[3].plot(random_coord_history['test_acc'], label='Coord. Descent')\n",
        "ax[3].legend()\n",
        "ax[3].set_title('Test Accuracy')\n",
        "ax[3].set_xlabel('Epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5k9kV6J-OPBg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "h06d58iDLGnE",
        "EbSP-OSBbsYv",
        "4GCUI13HZdr8"
      ],
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}